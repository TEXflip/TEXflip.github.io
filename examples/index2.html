<!DOCTYPE html>
<html>

<head>
    <script>
        function load_canvas(camera, stream_settings) {
            camera.play();
            let s_height = stream_settings.height;
            let s_width = stream_settings.width;
            // 512Ã—512 Canvas with WebGL context
            var canvas = document.getElementById("maincanvas");
            canvas.width = s_width;
            canvas.height = s_height;
            var gl = canvas.getContext("webgl");
            gl.viewport(0, 0, canvas.width, canvas.height);

            // Vertex shader: Identity map
            var vshader = gl.createShader(gl.VERTEX_SHADER);
            gl.shaderSource(vshader,
                "attribute vec2 p;" +
                "void main(){" +
                "    gl_Position = vec4(p,0,1);" +
                "}");
            gl.compileShader(vshader);

            // Fragment shader: sample video texture, change colors
            var fshader = gl.createShader(gl.FRAGMENT_SHADER);
            gl.shaderSource(fshader,
                "precision mediump float;" +
                "uniform sampler2D data; " +
                "void main() {" +
                `vec3 px = texture2D(data, gl_FragCoord.xy / vec2(${s_width},${s_height})).xyz;` +
                "float sum = px.x + px.y + px.z;" +
                // "px.x = px.y" +
                // "if (sum*0.33 < 0.2) {px.xyz=vec3(0.);}" +
                `gl_FragColor=vec4(px.x, px.y, px.z, 1.);` +
                "}");
            gl.compileShader(fshader);
            var compiled = gl.getShaderParameter(fshader, gl.COMPILE_STATUS);
            console.log('Shader compiled successfully: ' + compiled);
            var compilationLog = gl.getShaderInfoLog(fshader);
            console.log('Shader compiler log: ' + compilationLog);

            // Create and link program
            var program = gl.createProgram();
            gl.attachShader(program, vshader);
            gl.attachShader(program, fshader);
            gl.linkProgram(program);
            gl.useProgram(program);

            // Vertices: A screen-filling quad made from two triangles
            gl.bindBuffer(gl.ARRAY_BUFFER, gl.createBuffer());
            gl.bufferData(gl.ARRAY_BUFFER, new Float32Array([-1, -1, 1, -1, -1, 1, -1, 1, 1, -1, 1, 1]), gl.STATIC_DRAW);
            gl.enableVertexAttribArray(0);
            gl.vertexAttribPointer(0, 2, gl.FLOAT, false, 0, 0);

            // Texture to contain the video data
            var texture = gl.createTexture();
            gl.bindTexture(gl.TEXTURE_2D, texture);
            gl.pixelStorei(gl.UNPACK_FLIP_Y_WEBGL, true);
            gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);
            gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);
            gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.LINEAR);
            gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, gl.LINEAR);

            // Bind texture to the "data" argument to the fragment shader
            var param = gl.getActiveUniform(program, 0); // data bind point
            gl.uniform1i(gl.getUniformLocation(program, "data"), 0);
            gl.activeTexture(gl.TEXTURE0);
            gl.bindTexture(gl.TEXTURE_2D, texture);

            // Repeatedly pull camera data and render
            function animate() {
                gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGB, gl.RGB, gl.UNSIGNED_BYTE, camera);
                gl.drawArrays(gl.TRIANGLES, 0, 6);
                requestAnimationFrame(animate);
                if (camera.paused || camera.ended) {
                    camera.play();
                }
            }
            animate();
        }

        function main() {
            // Capture webcam input using invisible `video` element
            // Adapted from p5js.org/examples/3d-shader-using-webcam.html
            let camera = document.getElementById("camera");

            // Ask user permission to record their camera
            navigator.mediaDevices.getUserMedia({ video: 1, audio: 0 }).then(
                (stream) => {
                    try {
                        if ('srcObject' in camera)
                            camera.srcObject = stream;
                        else
                            camera.src = window.URL.createObjectURL(stream);
                    } catch (err) {
                        camera.src = stream;
                    }
                    let stream_settings = stream.getVideoTracks()[0].getSettings();
                    // console.log(stream_settings);
                    load_canvas(camera, stream_settings);
                }).catch(
                    (err) => {
                        console.log(err);
                        load_canvas(camera, { height: camera.videoHeight, width: camera.videoWidth });
                    }
                );
        }
    </script>
</head>

<body onload="javascript:main()">
    <canvas id='maincanvas'></canvas>
    <video id='camera' visible="False" style="display:none;" controls="true" playsinline="" crossorigin="anonymous"
        muted="muted">
        <source src="../assets/fingers.mov" type="video/mp4">
    </video>
</body>

</html>